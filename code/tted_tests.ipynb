{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cc7dad8-f70a-4e2f-9632-5bfeed842777",
   "metadata": {},
   "source": [
    "# A BERT-based algorithm for edit distance between text trees\n",
    "\n",
    "This notebook contains the implementation of a simple yet informative metric for text tree comparison. This way of text tree similarity measurement can be used, for example, to compare salient sentence-based mind maps generated by a neural network with reference maps. The way this algorithm works is by applying the Zhang-Shasha algorithm for tree edit distance to text trees, using semantic similarity as the cost of node updates. To measure semantic similarity of sentences in tree nodes, we use a BERT-like language model's embeddings of the sentences, given the context of all parent nodes if available, and compare these embeddings directly.\n",
    "\n",
    "The Zhang-Shasha algorithm implementation is taken from the `zss` Python library developed by Tim Henderson and Steve Johnson (2013)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2530439a-0f83-4f55-b8f4-06a96d02fbd2",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4243aa5-af88-4611-b528-5f891595f136",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\fedor\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\fedor\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\fedor\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\fedor\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\fedor\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 321, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"C:\\Users\\fedor\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\fedor\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\fedor\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\fedor\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\fedor\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\fedor\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\fedor\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\fedor\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\fedor\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\fedor\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\fedor\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\fedor\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\fedor\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3311, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\fedor\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3493, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\fedor\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\fedor\\AppData\\Local\\Temp\\ipykernel_25108\\2827337824.py\", line 1, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"C:\\Users\\fedor\\anaconda3\\Lib\\site-packages\\matplotlib\\__init__.py\", line 161, in <module>\n",
      "    from . import _api, _version, cbook, _docstring, rcsetup\n",
      "  File \"C:\\Users\\fedor\\anaconda3\\Lib\\site-packages\\matplotlib\\rcsetup.py\", line 27, in <module>\n",
      "    from matplotlib.colors import Colormap, is_color_like\n",
      "  File \"C:\\Users\\fedor\\anaconda3\\Lib\\site-packages\\matplotlib\\colors.py\", line 57, in <module>\n",
      "    from matplotlib import _api, _cm, cbook, scale\n",
      "  File \"C:\\Users\\fedor\\anaconda3\\Lib\\site-packages\\matplotlib\\scale.py\", line 22, in <module>\n",
      "    from matplotlib.ticker import (\n",
      "  File \"C:\\Users\\fedor\\anaconda3\\Lib\\site-packages\\matplotlib\\ticker.py\", line 143, in <module>\n",
      "    from matplotlib import transforms as mtransforms\n",
      "  File \"C:\\Users\\fedor\\anaconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 49, in <module>\n",
      "    from matplotlib._path import (\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\__init__.py:161\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[1;32m--> 161\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sanitize_sequence\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\rcsetup.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ls_mapper\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Colormap, is_color_like\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fontconfig_pattern\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_fontconfig_pattern\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\colors.py:57\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _cm, cbook, scale\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_color_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BASE_COLORS, TABLEAU_COLORS, CSS4_COLORS, XKCD_COLORS\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_ColorMapping\u001b[39;00m(\u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\scale.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _docstring\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mticker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     NullFormatter, ScalarFormatter, LogFormatterSciNotation, LogitFormatter,\n\u001b[0;32m     24\u001b[0m     NullLocator, LogLocator, AutoLocator, AutoMinorLocator,\n\u001b[0;32m     25\u001b[0m     SymmetricalLogLocator, AsinhLocator, LogitLocator)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Transform, IdentityTransform\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mScaleBase\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\ticker.py:143\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms \u001b[38;5;28;01mas\u001b[39;00m mtransforms\n\u001b[0;32m    145\u001b[0m _log \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    147\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTickHelper\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFixedFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    148\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNullFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFuncFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatStrFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    149\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStrMethodFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScalarFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    155\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultipleLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaxNLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAutoMinorLocator\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    156\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSymmetricalLogLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAsinhLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogitLocator\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\transforms.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inv\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_path\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     affine_transform, count_bboxes_overlapping_bbox, update_path_extents)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m     53\u001b[0m DEBUG \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, SimilarityFunction\n",
    "\n",
    "from tted.tree_format import Node, tree_with_context, json_to_node\n",
    "from tted.computation import text_tree_distance, text_tree_distance_w_o_precomputation\n",
    "from tted.baseline import baseline_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfc28a0-cf33-4535-a064-e35b85e783d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot formatting\n",
    "plt.rcParams['font.family'] = 'DejaVu Serif'\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "plt.rcParams['lines.markersize'] = 12\n",
    "plt.rcParams['xtick.labelsize'] = 24\n",
    "plt.rcParams['ytick.labelsize'] = 24\n",
    "plt.rcParams['legend.fontsize'] = 24\n",
    "plt.rcParams['axes.titlesize'] = 36\n",
    "plt.rcParams['axes.labelsize'] = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7285ec1f-60ec-49c1-9b14-212967db34bd",
   "metadata": {},
   "source": [
    "We will use text trees stored in the JSON format as in the following example:\n",
    "```json\n",
    "{\n",
    "  \"A new algorithm for text tree edit distance based on Zhang-Shasha's algorithm and BERT-like model embedding similarity.\": {\n",
    "    \"The algorithm's novelty is in its similarity measure based on BERT-like model embeddings.\": {\n",
    "      \"Embedding distance is used as a measure of semantic similarity.\": {},\n",
    "      \"The language model allows to capture semantic meaning of sentences and model their similarity.\": {}\n",
    "    },\n",
    "    \"Zhang-Shasha's algorithm is used to compute tree edit distance with new edit costs.\": {\n",
    "      \"Semantic similarity is used as the update cost in the algorithm.\": {},\n",
    "      \"The costs of insertion and removal of nodes are defined as the similarity of the node and an empty sentence.\": {}\n",
    "    },\n",
    "    \"The proposed algorithm is presented as a more informative metric of similarity between text trees.\": {\n",
    "      \"The current ways of comparing text trees overlook their tree structure or the meaning of their labels.\": {},\n",
    "      \"This new method can be used, for example, to compare mind maps or hierarchical summaries.\": {}\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "We use the similarity metric from \"Coherence Graph Guidance for Mind-Map Generation\" (Zhang et al., 2024) as a baseline for comaprison. The full original code from this paper can be found at https://github.com/Cyno2232/CMGN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ad8b85-5092-4585-a1d2-08451aae951b",
   "metadata": {},
   "source": [
    "## Basic tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57bcaf9-f6e8-4cbd-b58a-b017cda31fe4",
   "metadata": {},
   "source": [
    "Below we provide an example use case of the functions above utilizing a model from `sentence_transformers`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb018879-8685-4c82-9ecb-fb9fb3869dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = (\n",
    "    Node('We present a new metric for text tree comparison.', depth=0)\n",
    "        .addkid(Node('It uses Zhang-Shasha\\'s algorithm and a BERT-like model.', depth=1)\n",
    "            .addkid(Node('Zhang-Shasha\\'s algorithm is used to measure tree edit distance effectively.', depth=2))\n",
    "            .addkid(Node('The BERT-like model is used to measure semantic similarity.', depth=2)))\n",
    "        .addkid(Node('The algorithm is presented as an informative metric for text tree comparison.', depth=1)\n",
    "            .addkid(Node('There hasn\\'t yet been a metric that allows to compare tree-structured text data such as mind maps informatively.', depth=2))\n",
    "            .addkid(Node('This metric can be used, for example, to evaluate automatic salient sentence-based mind map generation.', depth=2)))\n",
    ")\n",
    "\n",
    "B = (\n",
    "    Node('A new metric for text tree comparison based on tree edit distance and semantic similarity.', depth=0)\n",
    "        .addkid(Node('Zhang-Shasha\\'s algorithm is used to compute tree edit distance.', depth=1))\n",
    "        .addkid(Node('Semantic similarity is measured using a BERT-like language model.', depth=1)\n",
    "            .addkid(Node('To measure it, the sentences with all parent nodes as context are passed to the language model.', depth=2))\n",
    "            .addkid(Node('Semantic similarity is measured as the similarity of the model\\'s embeddings of the sentences.', depth=2)))\n",
    "        .addkid(Node('This metric can be used to compare text trees.', depth=1)\n",
    "            .addkid(Node('For example, it can be utilized in automatic mind map generation evaluation against reference maps.', depth=2)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f830f96-2097-4453-be3d-124c3600115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/paraphrase-distilroberta-base-v1')\n",
    "def cos_dist(a_embedding, b_embedding):\n",
    "        return float(1 - model.similarity(a_embedding, b_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5f3488-843d-4772-a73b-6637fdb042af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "AB_dist = text_tree_distance(A, B, model.encode, cos_dist)\n",
    "print(AB_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75758be-0660-4299-9b0c-88b4b0a53c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "AB_dist = text_tree_distance_w_o_precomputation(A, B, model.encode, cos_dist)\n",
    "print(AB_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d6e96c-1e00-4bd8-a340-cf312299b34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "AB_base_dist = baseline_distance(A, B)\n",
    "print(AB_base_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6163d31b-5e56-4cd2-876d-232b26c1bb28",
   "metadata": {},
   "source": [
    "## Main experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ad248f-b863-4b85-8985-3bf94d925a3f",
   "metadata": {},
   "source": [
    "Now we can run a couple of experiments to evaluate these two metrics on simple test cases. We will compare the methods on three text tree sets, each based on the tree `C` from the example above:\n",
    "1) A set of trees that are identical in semantic meaning and structure, but the sentences in the tree nodes are paraphrased;\n",
    "2) A set of trees that are formed from the same sentences, but in different tree order;\n",
    "3) A set of trees that are similar in structure and wording but significantly different in meaning.\n",
    "\n",
    "For each set of trees we compute pairwise similarity scores with our metric and the baseline method. The goal is to capture the difference in meaning and structure of the trees while minimizing the distance between trees that are, in a sense, paraphrases of each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d72028-5b5b-4170-8740-ae0bd802d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(method, dist_args=None):\n",
    "    scores = {}\n",
    "    test_cases = ['paraphrase', 'meaning', 'restructure']\n",
    "\n",
    "    total_time = 0\n",
    "    for test_case in test_cases:\n",
    "        path = 'data/' + test_case + '/' + test_case + '_'\n",
    "        scores[test_case] = []\n",
    "\n",
    "        trees = []\n",
    "        for i in range(5):\n",
    "            trees.append(json_to_node(path + str(i) + '.json'))\n",
    "\n",
    "        start_time = time.time()\n",
    "        for i in range(4):\n",
    "            for j in range(i+1, 5):\n",
    "                if method == 'tted':\n",
    "                    scores[test_case].append(text_tree_distance(trees[i], trees[j], *dist_args))\n",
    "                elif method == 'baseline':\n",
    "                    scores[test_case].append(baseline_distance(trees[i], trees[j]))\n",
    "                elif method == 'tted_w_o_precomputation':\n",
    "                    scores[test_case].append(text_tree_distance_w_o_precomputation(trees[i], trees[j], *dist_args))\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "        total_time += time.time() - start_time\n",
    "\n",
    "    return scores, total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb0710e-ceb5-4f96-a637-79597c0c012c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scores(scores, plot_title, filename):\n",
    "    fig, ax = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "    ax.boxplot(scores.values(), vert=False)\n",
    "\n",
    "    ax.set_xlabel('Distance scores')\n",
    "    ax.set_yticklabels(scores.keys())\n",
    "    ax.grid()\n",
    "    ax.set_title(plot_title)\n",
    "\n",
    "    fig.savefig('../img/' + filename, bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84656d1a-b3e7-4559-a0c2-04e125cfa1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_frame(scores, method_name):\n",
    "    results_array = [method_name]\n",
    "    \n",
    "    for exp in ('paraphrase', 'meaning', 'restructure'):\n",
    "        results_array.append(np.mean(scores[exp]))\n",
    "        results_array.append(np.std(scores[exp]))\n",
    "    for exp in ('meaning', 'restructure'):\n",
    "        results_array.append(np.mean(scores['paraphrase']) / np.mean(scores[exp]))\n",
    "        results_array.append(np.sqrt((np.std(scores['paraphrase']) / np.mean(scores['paraphrase']))**2 +\\\n",
    "                                     (np.std(scores[exp]) / np.mean(scores[exp]))**2) * np.mean(scores['paraphrase']) / np.mean(scores[exp]))\n",
    "\n",
    "    results_array = [results_array]\n",
    "    frame = pd.DataFrame(results_array, columns=['Method', \n",
    "                                                 'Paraphrase mean', \n",
    "                                                 'Paraphrase std', \n",
    "                                                 'Meaning mean', \n",
    "                                                 'Meaning std', \n",
    "                                                 'Restructure mean',\n",
    "                                                 'Restructure std',\n",
    "                                                 'R_2 score',\n",
    "                                                 'R_2 std',\n",
    "                                                 'R_3 std',\n",
    "                                                 'R_3 std'])\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e94c846-cb6f-4ded-8a76-b8363258bd64",
   "metadata": {},
   "source": [
    "Below are our experiments with several language models and distance metrics, with and without context usage, in comparison to the baseline method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8907504b-e2e6-45ee-b5a1-67b069eb1259",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_dict = {}\n",
    "times_dict = {}\n",
    "\n",
    "scores_dict['baseline'], times_dict['baseline'] = run_test('baseline')\n",
    "\n",
    "for model_name in ['sentence-transformers/paraphrase-distilroberta-base-v1',\n",
    "              'sentence-transformers/allenai-specter',\n",
    "              'sentence-transformers/all-mpnet-base-v2',\n",
    "              'sentence-transformers/paraphrase-multilingual-mpnet-base-v2']:\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    # The default similarity function for all of the models above is the cosine similarity function\n",
    "    def dist(a_embedding, b_embedding):\n",
    "        return float(1 - model.similarity(a_embedding, b_embedding))\n",
    "\n",
    "    dist_args = [model.encode, dist, True]\n",
    "    scores_dict[model_name], times_dict[model_name] = run_test('tted', dist_args)\n",
    "\n",
    "# Experiment with different distance measures\n",
    "for sim_measure, measure_name in zip([SimilarityFunction.EUCLIDEAN, SimilarityFunction.MANHATTAN], ['euclidian', 'manhattan']):\n",
    "    model.similarity_fn_name = sim_measure\n",
    "    def dist(embedding_a, embedding_b):\n",
    "        return float(-model.similarity(embedding_a, embedding_b))\n",
    "        \n",
    "    scores_dict[measure_name], times_dict[measure_name] = run_test('tted', [model.encode, dist, True])\n",
    "\n",
    "# Experiment without context usage\n",
    "model.similarity_fn_name = SimilarityFunction.COSINE\n",
    "def dist(a_embedding, b_embedding):\n",
    "        return float(1 - model.similarity(a_embedding, b_embedding))\n",
    "\n",
    "dist_args = [model.encode, dist, False]\n",
    "scores_dict['Without context'], times_dict['Without context'] = run_test('tted', dist_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218511c2-d754-4775-9a19-ea66fadcb7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6e616b-5b0e-469a-98be-31bae7d4d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_dict = {}\n",
    "for exp_name, method_name in zip(scores_dict.keys(), ['Baseline method',\n",
    "                                                    'TTED with paraphrase DistilRoBERTa',\n",
    "                                                    'TTED with SPECTER',\n",
    "                                                    'TTED with untuned MPNet',\n",
    "                                                    'TTED with paraphrase MPNet',\n",
    "                                                    'TTED with MPNet and Euclidian distance',\n",
    "                                                    'TTED with MPNet and Manhattan distance',\n",
    "                                                    'TTED with MPNet without context']):\n",
    "    frames_dict[exp_name] = result_frame(scores_dict[exp_name], method_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5989aceb-6fce-4adf-b9e7-cb7db269a0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_frame = pd.concat(frames_dict.values())\n",
    "final_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d20e88-97c1-448b-96d1-26ee6ccb6a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(scores_dict['sentence-transformers/paraphrase-multilingual-mpnet-base-v2'], \n",
    "            'TTED with fine-tuned MPNet',\n",
    "            '../paper/img/paraphrase_mpnet_results.png')\n",
    "plot_scores(scores_dict['baseline'], 'Baseline method', '../paper/img/baseline_results.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
